{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03dcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install \"langchain==0.2.11\"\n",
    "!pip install \"langchain-core==0.2.43\"\n",
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36372fa5",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7176d35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Basic libraries\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Formatting\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Import Google Generative AI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "\n",
    "# LangChain Components\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSequence\n",
    "\n",
    "# usually we start loading with environment variables\n",
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc4079",
   "metadata": {},
   "source": [
    "# API Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e7cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60cbde42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model(prompt_txt, params=None):\n",
    "\n",
    "    model_id = \"gemini-2.0-flash\"\n",
    "\n",
    "    default_params = {\n",
    "        \"temperature\" : 0,\n",
    "        \"max_tokens\" : None, \n",
    "        \"timeout\" : None, \n",
    "        \"max_retries\" : 2\n",
    "    }\n",
    "\n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "\n",
    "    # Create LLM directly\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model = model_id, \n",
    "        temperature = default_params[\"temperature\"], \n",
    "        max_tokens = default_params[\"max_tokens\"], \n",
    "        timeout = default_params[\"timeout\"], \n",
    "        max_retries = default_params[\"max_retries\"]\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(prompt_txt)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cceb230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected argument 'params' provided to ChatGoogleGenerativeAI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"J'adore la programmation.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--3d09e71f-8138-4d60-91b5-f8d68b74b030-0' usage_metadata={'input_tokens': 19, 'output_tokens': 7, 'total_tokens': 26, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "ai_msg = llm_model(prompt_txt = [(\"system\", \"You are a helpful assistant that translates English to French. Translate the user sentense\"), \n",
    "    (\"human\", \"I love programming\")])\n",
    "print(ai_msg)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bf0a3",
   "metadata": {},
   "source": [
    "# Prompt Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a90cc1",
   "metadata": {},
   "source": [
    "#### 1. Basic Prompt\n",
    "\n",
    "A basic prompt is the simplest form of prompting, where you provide a short text or phrase to the model without any special formatting or instructions. The model generates a continuation based on patterns it has learned during training. Basic prompts are useful for exploring the model's capabilities and understanding how it naturally responds to minimal input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89d13487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt : The wind is  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The wind is **blowing**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_tokens\" : 128, \n",
    "    \"temperature\" : 0.5, \n",
    "    \"max_retries\" : 2\n",
    "}\n",
    "\n",
    "prompt = \"The wind is \"\n",
    "\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt : {prompt} \\n\")\n",
    "print(f\"response : {display(Markdown(response.content))} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4786deb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt : The future of artificial intellgence is \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The future of artificial intelligence is a topic of much discussion and speculation, with potential impacts across nearly every aspect of human life. Here's a breakdown of some key areas:\n",
       "\n",
       "**Potential Positive Impacts:**\n",
       "\n",
       "*   **Automation and Efficiency:** AI can automate repetitive tasks, freeing up humans for more creative and strategic work. This could lead to increased productivity and economic growth.\n",
       "*   **Healthcare Advancements:** AI can assist in diagnosis, drug discovery, personalized medicine, and robotic surgery, potentially leading to better patient outcomes and more efficient healthcare systems.\n",
       "*   **Improved Decision-Making:** AI algorithms can analyze vast amounts of data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : None \n",
      "\n",
      "prompt : Once upon a time in a distant galaxy \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Once upon a time in a distant galaxy, far, far beyond the swirling nebulae of known space, existed a planet called Xylos. Xylos wasn't a typical planet of verdant forests or shimmering oceans. Instead, it was a world sculpted entirely from crystal. Towering spires of amethyst pierced the cerulean sky, while canyons of glittering quartz snaked across the landscape. The very air hummed with a low, resonant frequency, a song of the crystals themselves.\n",
       "\n",
       "The inhabitants of Xylos were the Luminians, beings of pure light and energy, housed within crystalline shells. They were not born"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : None \n",
      "\n",
      "prompt : The benefits of sustainable energy include \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The benefits of sustainable energy are numerous and span environmental, economic, and social aspects. Here's a breakdown:\n",
       "\n",
       "**Environmental Benefits:**\n",
       "\n",
       "*   **Reduced Greenhouse Gas Emissions:** This is the most significant benefit. Sustainable energy sources like solar, wind, hydro, and geothermal produce little to no greenhouse gases during operation, mitigating climate change.\n",
       "*   **Improved Air Quality:**  Unlike fossil fuels, sustainable energy sources don't release harmful air pollutants like sulfur dioxide, nitrogen oxides, and particulate matter, leading to cleaner air and reduced respiratory problems.\n",
       "*   **Water Conservation:** Many sustainable energy technologies, particularly solar and wind"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"The future of artificial intellgence is\",\n",
    "    \"Once upon a time in a distant galaxy\",\n",
    "    \"The benefits of sustainable energy include\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = llm_model(prompt, params)\n",
    "    print(f\"prompt : {prompt} \\n\")\n",
    "    print(f\"response : {display(Markdown(response.content))} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e1b9d",
   "metadata": {},
   "source": [
    "#### 2. Zero-Shot Prompts\n",
    "\n",
    "Zero-shot prompting is a technique where the model performs a task without any examples or prior specific training. This approach tests the model's ability to understand instructions and apply its knowledge to a new context without demonstration. Zero-shot prompts typically include clear instructions about what the model should do, allowing it to leverage its pre-trained knowledge effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c48a497",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
